[
  {
    "objectID": "matching.html",
    "href": "matching.html",
    "title": "matching",
    "section": "",
    "text": "source\n\nbox_iou_batch\n\n box_iou_batch (boxes_true:numpy.ndarray, boxes_detection:numpy.ndarray)\n\nCompute the Intersection over Union (IoU) between two sets of bounding boxes.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nboxes_true\nndarray\nGround truth bounding boxes, shape (N, 4) format (x_min, y_min, x_max, y_max).\n\n\nboxes_detection\nndarray\nDetected bounding boxes, shape (M, 4), format (x_min, y_min, x_max, y_max).\n\n\nReturns\nndarray\nIoU matrix of shape (N, M) where each element (i, j) represents the IoU between boxes_true[i] and boxes_detection[j].\n\n\n\n\nsource\n\n\nindices_to_matches\n\n indices_to_matches (cost_matrix:numpy.ndarray, indices:tuple,\n                     thresh:float)\n\nExtract matched and unmatched indices based on a threshold.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ncost_matrix\nndarray\nThe matrix of costs.\n\n\nindices\ntuple\nIndices of potential matches.\n\n\nthresh\nfloat\nThreshold for valid matches.\n\n\nReturns\ntuple\nContains three elements: Matched indices., Unmatched indices from the first set. Unmatched indices from the second set.\n\n\n\n\nsource\n\n\nlinear_assignment\n\n linear_assignment (cost_matrix:numpy.ndarray, thresh:float)\n\nPerform linear assignment to minimize the total cost.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ncost_matrix\nndarray\nThe matrix of costs.\n\n\nthresh\nfloat\nThreshold for valid matches.\n\n\nReturns\ntuple\nContains three elements: Matched indices, Unmatched indices from the first set., Unmatched indices from the second set.\n\n\n\n\nsource\n\n\nious\n\n ious (atlbrs, btlbrs)\n\nCompute the IoU between two sets of bounding boxes.\n\n\n\n\nType\nDetails\n\n\n\n\natlbrs\n\nList of bounding boxes from the first set.\n\n\nbtlbrs\n\nList of bounding boxes from the second set.\n\n\nReturns\nndarray\nIoU matrix.\n\n\n\n\nsource\n\n\niou_distance\n\n iou_distance (atracks:list, btracks:list)\n\nCompute the cost matrix based on IoU for two sets of tracks.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\natracks\nlist\nList of tracks from the first set. Each track can be an ndarray or an object with a ‘tlbr’ attribute.\n\n\nbtracks\nlist\nList of tracks from the second set. Each track can be an ndarray or an object with a ‘tlbr’ attribute.\n\n\nReturns\nndarray\nCost matrix where each element (i, j) represents the cost of associating atracks[i] with btracks[j].\n\n\n\n\nsource\n\n\nmatch_detections_with_tracks\n\n match_detections_with_tracks (tlbr_boxes:numpy.ndarray,\n                               track_ids:numpy.ndarray,\n                               tracks:List[cjm_byte_track.strack.STrack])\n\nMatch detected bounding boxes with existing tracks using Intersection Over Union (IOU).\nNote: - If a detected bounding box does not match any existing track (i.e., IOU is zero), its corresponding track ID remains unchanged.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ntlbr_boxes\nndarray\nAn array of detected bounding boxes, represented as [top, left, bottom, right].\n\n\ntrack_ids\nndarray\nAn array of track IDs corresponding to the input bounding boxes.\n\n\ntracks\nList\nA list of track objects representing the current tracked objects.\n\n\nReturns\nndarray\nAn array of updated track IDs where the detections are matched with the existing tracks."
  },
  {
    "objectID": "basetrack.html",
    "href": "basetrack.html",
    "title": "basetrack",
    "section": "",
    "text": "source\n\nTrackState\n\n TrackState (value, names=None, module=None, qualname=None, type=None,\n             start=1)\n\nEnum class to represent the possible states of a track.\nAttributes:\n\nNew: The initial state of the track when it’s just detected.\nTracked: The state when the track is being actively tracked.\nLost: The state when the track is lost or not detected in the current frame.\nRemoved: The state when the track is removed from the tracking system.\n\n\nsource\n\n\nBaseTrack\n\n BaseTrack ()\n\nBase class for a track in a tracking system.\nThis class provides the basic functionalities and properties for a track, such as its unique ID, state, history, features, and related functions. Derived classes should implement the activate, predict, and update methods.\nAttributes:\n\n_count (int): Class-level counter to generate unique IDs for tracks.\n\n\nsource\n\n\nBaseTrack.end_frame\n\n BaseTrack.end_frame ()\n\nReturns the current frame number as the end frame of the track.\n\nsource\n\n\nBaseTrack.next_id\n\n BaseTrack.next_id ()\n\nGenerates and returns the next unique track ID.\n\nsource\n\n\nBaseTrack.activate\n\n BaseTrack.activate (*args)\n\nActivates the track. This method should be implemented by derived classes.\nRaises: NotImplementedError: If the method is not implemented by derived classes.\n\nsource\n\n\nBaseTrack.predict\n\n BaseTrack.predict ()\n\nPredicts the next state of the track. This method should be implemented by derived classes.\nRaises: NotImplementedError: If the method is not implemented by derived classes.\n\nsource\n\n\nBaseTrack.update\n\n BaseTrack.update (*args, **kwargs)\n\nUpdates the state of the track based on new observations. This method should be implemented by derived classes.\nRaises: NotImplementedError: If the method is not implemented by derived classes.\n\nsource\n\n\nBaseTrack.mark_lost\n\n BaseTrack.mark_lost ()\n\nMarks the track as lost.\n\nsource\n\n\nBaseTrack.mark_removed\n\n BaseTrack.mark_removed ()\n\nMarks the track as removed."
  },
  {
    "objectID": "byte_tracker.html",
    "href": "byte_tracker.html",
    "title": "byte_tracker",
    "section": "",
    "text": "source\n\nBYTETracker\n\n BYTETracker (track_thresh:float=0.25, track_buffer:int=30,\n              match_thresh:float=0.8, frame_rate:int=30)\n\nBYTETracker is a class for tracking objects in video streams using bounding box detections, with methods for processing and updating tracks based on detection results and IoU matching.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntrack_thresh\nfloat\n0.25\nThreshold value for tracking.\n\n\ntrack_buffer\nint\n30\nSize of buffer for tracking.\n\n\nmatch_thresh\nfloat\n0.8\nThreshold value for matching tracks to detections.\n\n\nframe_rate\nint\n30\nFrame rate of the input video stream.\n\n\n\n\nsource\n\n\nBYTETracker.__init__\n\n BYTETracker.__init__ (track_thresh:float=0.25, track_buffer:int=30,\n                       match_thresh:float=0.8, frame_rate:int=30)\n\nInitializes the BYTETracker.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntrack_thresh\nfloat\n0.25\nThreshold value for tracking.\n\n\ntrack_buffer\nint\n30\nSize of buffer for tracking.\n\n\nmatch_thresh\nfloat\n0.8\nThreshold value for matching tracks to detections.\n\n\nframe_rate\nint\n30\nFrame rate of the input video stream.\n\n\n\n\nsource\n\n\nBYTETracker._process_output\n\n BYTETracker._process_output (output_results)\n\nProcess the output results to separate scores and bounding boxes.\n\n\n\n\nType\nDetails\n\n\n\n\noutput_results\n\nDetection results.\n\n\nReturns\ntuple\nscores and bounding boxes.\n\n\n\n\nsource\n\n\nBYTETracker._scale_bboxes\n\n BYTETracker._scale_bboxes (img_info:tuple, img_size:tuple, bboxes:list)\n\nScale bounding boxes based on image size.\n\n\n\n\nType\nDetails\n\n\n\n\nimg_info\ntuple\nOriginal height and width of the image.\n\n\nimg_size\ntuple\nTarget size.\n\n\nbboxes\nlist\nList of bounding boxes.\n\n\nReturns\nlist\nScaled bounding boxes.\n\n\n\n\nsource\n\n\nBYTETracker._get_detections\n\n BYTETracker._get_detections (dets:list, scores_keep:list)\n\nConvert bounding boxes to STrack objects.\n\n\n\n\nType\nDetails\n\n\n\n\ndets\nlist\nList of detections.\n\n\nscores_keep\nlist\nScores for the detections.\n\n\nReturns\nlist\nList of STrack objects.\n\n\n\n\nsource\n\n\nBYTETracker._update_tracked_stracks\n\n BYTETracker._update_tracked_stracks ()\n\nUpdate the list of tracked and unconfirmed tracks.\n\nsource\n\n\nBYTETracker._match_tracks_to_detections\n\n BYTETracker._match_tracks_to_detections (stracks:list, detections:list,\n                                          thresh:float)\n\nMatch tracks to detections using IOU.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nstracks\nlist\nList of tracks.\n\n\ndetections\nlist\nList of detections.\n\n\nthresh\nfloat\nIOU threshold for matching.\n\n\nReturns\ntuple\nMatches and unmatched tracks and detections.\n\n\n\n\nsource\n\n\nBYTETracker._update_tracks\n\n BYTETracker._update_tracks (stracks:list, detections:list, matches:list,\n                             refind_stracks:list, activated_stracks:list)\n\nUpdate tracks based on matches with detections.\n\n\n\n\nType\nDetails\n\n\n\n\nstracks\nlist\nList of tracks.\n\n\ndetections\nlist\nList of detections.\n\n\nmatches\nlist\nMatched track-detection pairs.\n\n\nrefind_stracks\nlist\nList to add refind tracks.\n\n\nactivated_stracks\nlist\nList to add activated tracks.\n\n\n\n\nsource\n\n\nBYTETracker.update\n\n BYTETracker.update (output_results, img_info:tuple, img_size:tuple)\n\nUpdate the tracker based on new detections.\n\n\n\n\nType\nDetails\n\n\n\n\noutput_results\n\nDetection results.\n\n\nimg_info\ntuple\nOriginal height and width of the image.\n\n\nimg_size\ntuple\nTarget size.\n\n\nReturns\nlist\nList of activated tracks.\n\n\n\n\nsource\n\n\njoint_stracks\n\n joint_stracks (track_list_a:list, track_list_b:list)\n\nCombines two lists of tracks ensuring each track is unique based on its track_id.\n\n\n\n\nType\nDetails\n\n\n\n\ntrack_list_a\nlist\nThe first list of tracks.\n\n\ntrack_list_b\nlist\nThe second list of tracks.\n\n\nReturns\nlist\nA combined list of unique tracks.\n\n\n\n\nsource\n\n\nsub_stracks\n\n sub_stracks (track_list_a:list, track_list_b:list)\n\nSubtracts the tracks in track_list_b from track_list_a based on track_id.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ntrack_list_a\nlist\nThe list of tracks to subtract from.\n\n\ntrack_list_b\nlist\nThe list of tracks to subtract.\n\n\nReturns\nlist\nA list containing tracks from track_list_a that are not in track_list_b.\n\n\n\n\nsource\n\n\nremove_duplicate_stracks\n\n remove_duplicate_stracks (s_tracks_a:list, s_tracks_b:list)\n\nRemoves duplicate tracks from two lists based on a defined distance metric and time criteria.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ns_tracks_a\nlist\nThe first list of tracks.\n\n\ns_tracks_b\nlist\nThe second list of tracks.\n\n\nReturns\ntuple\nTwo lists of tracks with duplicates removed."
  },
  {
    "objectID": "strack.html",
    "href": "strack.html",
    "title": "strack",
    "section": "",
    "text": "source\n\nSTrack\n\n STrack (tlwh, score)\n\nA Simple Track object\n\n\n\n\n\n\n\n\nDetails\n\n\n\n\ntlwh\nList or array-like containing four values (top-left x, top-left y, width, height).\n\n\nscore\nThe confidence score of the detection.\n\n\n\n\nsource\n\n\nSTrack.__init__\n\n STrack.__init__ (tlwh, score)\n\nInitialize an STrack (Simple Track) object.\n\n\n\n\n\n\n\n\nDetails\n\n\n\n\ntlwh\nList or array-like containing four values (top-left x, top-left y, width, height).\n\n\nscore\nThe confidence score of the detection.\n\n\n\n\nsource\n\n\nSTrack.predict\n\n STrack.predict ()\n\nPredict the next state using Kalman filter.\n\nsource\n\n\nSTrack.multi_predict\n\n STrack.multi_predict (stracks)\n\nPredict the state for multiple tracks simultaneously using the shared Kalman filter.\n\n\n\n\nDetails\n\n\n\n\nstracks\nList of STrack objects.\n\n\n\n\nsource\n\n\nSTrack.activate\n\n STrack.activate (kalman_filter, frame_id)\n\nActivate the track.\n\n\n\n\nDetails\n\n\n\n\nkalman_filter\nKalmanFilter instance.\n\n\nframe_id\nID of the current frame.\n\n\n\n\nsource\n\n\nSTrack.re_activate\n\n STrack.re_activate (new_track, frame_id, new_id=False)\n\nReactivate a track with new details.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnew_track\n\n\nThe new STrack object with updated details.\n\n\nframe_id\n\n\nID of the current frame.\n\n\nnew_id\nbool\nFalse\nFlag to determine if a new ID should be assigned.\n\n\n\n\nsource\n\n\nSTrack.update\n\n STrack.update (new_track, frame_id)\n\nUpdate the track with new details.\n:param new_track: The new STrack object with updated details. :param frame_id: ID of the current frame.\n\nsource\n\n\nSTrack._update_track\n\n STrack._update_track (new_track, frame_id, new_id=False)\n\nInternal method to update track details.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnew_track\n\n\nThe new STrack object with updated details.\n\n\nframe_id\n\n\nID of the current frame.\n\n\nnew_id\nbool\nFalse\nFlag to determine if a new ID should be assigned.\n\n\n\n\nsource\n\n\nSTrack.tlwh_to_xyah\n\n STrack.tlwh_to_xyah (tlwh)\n\nConvert bounding box from (top-left x, top-left y, width, height) to (center x, center y, aspect ratio, height).\n\n\n\n\nDetails\n\n\n\n\ntlwh\nBounding box in tlwh format.\n\n\n\n\nsource\n\n\nSTrack.tlwh_to_tlbr\n\n STrack.tlwh_to_tlbr (tlwh)\n\nConvert bounding box from (top-left x, top-left y, width, height) to (top-left x, top-left y, bottom-right x, bottom-right y).\n\n\n\n\nDetails\n\n\n\n\ntlwh\nBounding box in tlwh format.\n\n\n\n\nsource\n\n\nSTrack.tlwh\n\n STrack.tlwh ()\n\nGet bounding box in (top-left x, top-left y, width, height) format.\n\nsource\n\n\nSTrack.tlbr\n\n STrack.tlbr ()\n\nGet bounding box in (top-left x, top-left y, bottom-right x, bottom-right y) format."
  },
  {
    "objectID": "kalman_filter.html",
    "href": "kalman_filter.html",
    "title": "kalman_filter",
    "section": "",
    "text": "source\n\nKalmanFilter\n\n KalmanFilter ()\n\nA Kalman filter class designed for tracking bounding boxes in image space.\nAttributes:\n\nndim (int): The dimension of the state space.\n_motion_mat (ndarray): The motion model matrix.\n_update_mat (ndarray): The update matrix used for projecting state distribution to measurement space.\n_std_weight_position (float): Standard deviation weight for the position.\n_std_weight_velocity (float): Standard deviation weight for the velocity.\n\n\nsource\n\n\nKalmanFilter.__init__\n\n KalmanFilter.__init__ ()\n\nInitialize the Kalman filter with default parameters.\n\nsource\n\n\nKalmanFilter._create_std\n\n KalmanFilter._create_std (mean:numpy.ndarray)\n\nCompute standard deviations based on the mean.\n\n\n\n\nType\nDetails\n\n\n\n\nmean\nndarray\nThe mean values.\n\n\nReturns\nndarray\nThe computed standard deviations.\n\n\n\n\nsource\n\n\nKalmanFilter.initiate\n\n KalmanFilter.initiate (measurement:numpy.ndarray)\n\nInitialize a new track from an unassociated measurement.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nmeasurement\nndarray\nThe initial measurement for the track.\n\n\nReturns\ntuple\nThe mean and covariance of the initiated track.\n\n\n\n\nsource\n\n\nKalmanFilter.predict\n\n KalmanFilter.predict (mean:numpy.ndarray, covariance:numpy.ndarray)\n\nRun the Kalman filter prediction step.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nmean\nndarray\nThe current state mean.\n\n\ncovariance\nndarray\nThe current state covariance.\n\n\nReturns\ntuple\nThe predicted state mean and covariance.\n\n\n\n\nsource\n\n\nKalmanFilter.project\n\n KalmanFilter.project (mean:numpy.ndarray, covariance:numpy.ndarray)\n\nProject the state distribution to the measurement space.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nmean\nndarray\nThe current state mean.\n\n\ncovariance\nndarray\nThe current state covariance.\n\n\nReturns\ntuple\nThe mean and covariance in the measurement space.\n\n\n\n\nsource\n\n\nKalmanFilter.multi_predict\n\n KalmanFilter.multi_predict (mean:numpy.ndarray, covariance:numpy.ndarray)\n\nRun the Kalman filter prediction step for multiple measurements (Vectorized version).\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nmean\nndarray\nThe current state mean.\n\n\ncovariance\nndarray\nThe current state covariance.\n\n\nReturns\ntuple\nThe predicted state mean and covariance for multiple measurements.\n\n\n\n\nsource\n\n\nKalmanFilter.update\n\n KalmanFilter.update (mean:numpy.ndarray, covariance:numpy.ndarray,\n                      measurement:numpy.ndarray)\n\nRun the Kalman filter correction step.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nmean\nndarray\nThe predicted state mean.\n\n\ncovariance\nndarray\nThe predicted state covariance.\n\n\nmeasurement\nndarray\nThe new measurement.\n\n\nReturns\ntuple\nThe updated state mean and covariance after correction.\n\n\n\n\nsource\n\n\nKalmanFilter.gating_distance\n\n KalmanFilter.gating_distance (mean:numpy.ndarray,\n                               covariance:numpy.ndarray,\n                               measurements:numpy.ndarray,\n                               only_position:bool=False,\n                               metric:str='maha')\n\nCompute the gating distance between the state distribution and given measurements.\nRaises: ValueError: If an invalid distance metric is provided.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmean\nndarray\n\nThe state mean.\n\n\ncovariance\nndarray\n\nThe state covariance.\n\n\nmeasurements\nndarray\n\nThe given measurements.\n\n\nonly_position\nbool\nFalse\nIf True, consider only position in the gating distance. Defaults to False.\n\n\nmetric\nstr\nmaha\nThe metric to use for distance calculation (‘gaussian’ or ‘maha’). Defaults to ‘maha’.\n\n\nReturns\nndarray\n\nThe gating distances."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "cjm-byte-track",
    "section": "",
    "text": "A standalone Python implementation of the ByteTrack multi-object tracker based on the official implementation."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "cjm-byte-track",
    "section": "Install",
    "text": "Install\npip install cjm_byte_track"
  },
  {
    "objectID": "index.html#tutorial",
    "href": "index.html#tutorial",
    "title": "cjm-byte-track",
    "section": "Tutorial:",
    "text": "Tutorial:\n\nReal-Time Object Tracking with YOLOX and ByteTrack: Learn how to track objects across video frames with YOLOX and ByteTrack."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "cjm-byte-track",
    "section": "How to use",
    "text": "How to use\n# Import ByteTrack package\nfrom cjm_byte_track.core import BYTETracker\nfrom cjm_byte_track.matching import match_detections_with_tracks\n# Initialize a ByteTracker object\ntracker = BYTETracker(track_thresh=0.25, track_buffer=30, match_thresh=0.8, frame_rate=frame_fps)\n\nwith tqdm(total=frames, desc=\"Processing frames\") as pbar:\n    while video_capture.isOpened():\n        ret, frame = video_capture.read()\n        if ret:\n            \n            # Prepare an input image for inference\n            rgb_img, input_dims, offsets, min_img_scale, input_img = prepare_image_for_inference(frame, test_sz, max_stride)\n                        \n            # Convert the existing input image to NumPy format\n            input_tensor_np = np.array(input_img, dtype=np.float32).transpose((2, 0, 1))[None]/255\n\n            # Start performance counter`m\n            start_time = time.perf_counter()\n                        \n            # Run inference\n            outputs = session.run(None, {\"input\": input_tensor_np})[0]\n\n            # Process the model output\n            proposals = process_outputs(outputs, input_tensor_np.shape[input_dim_slice], bbox_conf_thresh)\n            \n            # Apply non-max suppression to the proposals with the specified threshold\n            proposal_indices = nms_sorted_boxes(calc_iou(proposals[:, :-2]), iou_thresh)\n            proposals = proposals[proposal_indices]\n            \n            bbox_list = (proposals[:,:4]+[*offsets, 0, 0])*min_img_scale\n            label_list = [class_names[int(idx)] for idx in proposals[:,4]]\n            probs_list = proposals[:,5]\n\n            # Update tracker with detections.\n            track_ids = [-1]*len(bbox_list)\n\n            # Convert to tlbr format\n            tlbr_boxes = bbox_list.copy()\n            tlbr_boxes[:, 2:4] += tlbr_boxes[:, :2]\n\n            # Update tracker with detections\n            tracks = tracker.update(\n                output_results=np.concatenate([tlbr_boxes, probs_list[:, np.newaxis]], axis=1),\n                img_info=rgb_img.size,\n                img_size=rgb_img.size)\n            track_ids = match_detections_with_tracks(tlbr_boxes=tlbr_boxes, track_ids=track_ids, tracks=tracks)\n\n            # End performance counter\n            end_time = time.perf_counter()\n            # Calculate the combined FPS for object detection and tracking\n            fps = 1 / (end_time - start_time)\n            # Display the frame rate in the progress bar\n            pbar.set_postfix(fps=fps)\n\n            # Filter object detections based on tracking results\n            bbox_list, label_list, probs_list, track_ids = zip(*[(bbox, label, prob, track_id) \n                                                                 for bbox, label, prob, track_id \n                                                                 in zip(bbox_list, label_list, probs_list, track_ids) if track_id != -1])\n\n            # Annotate the current frame with bounding boxes and tracking IDs\n            annotated_img = draw_bboxes_pil(\n                image=rgb_img, \n                boxes=bbox_list, \n                labels=[f\"{track_id}-{label}\" for track_id, label in zip(track_ids, label_list)],\n                probs=probs_list,\n                colors=[int_colors[class_names.index(i)] for i in label_list],  \n                font=font_file,\n            )\n            annotated_frame = cv2.cvtColor(np.array(annotated_img), cv2.COLOR_RGB2BGR)\n            \n            video_writer.write(annotated_frame)\n            pbar.update(1)\n        else:\n            break\nvideo_capture.release()\nvideo_writer.release()"
  }
]