{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: A standalone Python implementation of the [ByteTrack](https://arxiv.org/abs/2110.06864)\n",
    "  multi-object tracker based on the [official implementation](https://github.com/ifzhang/ByteTrack/tree/main/yolox/tracker).\n",
    "output-file: index.html\n",
    "title: cjm-byte-track\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standalone Python implementation of the [ByteTrack](https://arxiv.org/abs/2110.06864) multi-object tracker based on the [official implementation](https://github.com/ifzhang/ByteTrack/tree/main/yolox/tracker)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install cjm_byte_track\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial:\n",
    "* [**Real-Time Object Tracking with YOLOX and ByteTrack:**](https://christianjmills.com/posts/pytorch-train-object-detector-yolox-tutorial/byte-track/) \n",
    "Learn how to track objects across video frames with YOLOX and ByteTrack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Import ByteTrack package\n",
    "from cjm_byte_track.core import BYTETracker\n",
    "from cjm_byte_track.matching import match_detections_with_tracks\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Initialize a ByteTracker object\n",
    "tracker = BYTETracker(track_thresh=0.25, track_buffer=30, match_thresh=0.8, frame_rate=frame_fps)\n",
    "\n",
    "with tqdm(total=frames, desc=\"Processing frames\") as pbar:\n",
    "    while video_capture.isOpened():\n",
    "        ret, frame = video_capture.read()\n",
    "        if ret:\n",
    "            \n",
    "            # Prepare an input image for inference\n",
    "            rgb_img, input_dims, offsets, min_img_scale, input_img = prepare_image_for_inference(frame, test_sz, max_stride)\n",
    "                        \n",
    "            # Convert the existing input image to NumPy format\n",
    "            input_tensor_np = np.array(input_img, dtype=np.float32).transpose((2, 0, 1))[None]/255\n",
    "\n",
    "            # Start performance counter`m\n",
    "            start_time = time.perf_counter()\n",
    "                        \n",
    "            # Run inference\n",
    "            outputs = session.run(None, {\"input\": input_tensor_np})[0]\n",
    "\n",
    "            # Process the model output\n",
    "            proposals = process_outputs(outputs, input_tensor_np.shape[input_dim_slice], bbox_conf_thresh)\n",
    "            \n",
    "            # Apply non-max suppression to the proposals with the specified threshold\n",
    "            proposal_indices = nms_sorted_boxes(calc_iou(proposals[:, :-2]), iou_thresh)\n",
    "            proposals = proposals[proposal_indices]\n",
    "            \n",
    "            bbox_list = (proposals[:,:4]+[*offsets, 0, 0])*min_img_scale\n",
    "            label_list = [class_names[int(idx)] for idx in proposals[:,4]]\n",
    "            probs_list = proposals[:,5]\n",
    "\n",
    "            # Update tracker with detections.\n",
    "            track_ids = [-1]*len(bbox_list)\n",
    "\n",
    "            # Convert to tlbr format\n",
    "            tlbr_boxes = bbox_list.copy()\n",
    "            tlbr_boxes[:, 2:4] += tlbr_boxes[:, :2]\n",
    "\n",
    "            # Update tracker with detections\n",
    "            tracks = tracker.update(\n",
    "                output_results=np.concatenate([tlbr_boxes, probs_list[:, np.newaxis]], axis=1),\n",
    "                img_info=rgb_img.size,\n",
    "                img_size=rgb_img.size)\n",
    "            track_ids = match_detections_with_tracks(tlbr_boxes=tlbr_boxes, track_ids=track_ids, tracks=tracks)\n",
    "\n",
    "            # End performance counter\n",
    "            end_time = time.perf_counter()\n",
    "            # Calculate the combined FPS for object detection and tracking\n",
    "            fps = 1 / (end_time - start_time)\n",
    "            # Display the frame rate in the progress bar\n",
    "            pbar.set_postfix(fps=fps)\n",
    "\n",
    "            # Filter object detections based on tracking results\n",
    "            bbox_list, label_list, probs_list, track_ids = zip(*[(bbox, label, prob, track_id) \n",
    "                                                                 for bbox, label, prob, track_id \n",
    "                                                                 in zip(bbox_list, label_list, probs_list, track_ids) if track_id != -1])\n",
    "\n",
    "            # Annotate the current frame with bounding boxes and tracking IDs\n",
    "            annotated_img = draw_bboxes_pil(\n",
    "                image=rgb_img, \n",
    "                boxes=bbox_list, \n",
    "                labels=[f\"{track_id}-{label}\" for track_id, label in zip(track_ids, label_list)],\n",
    "                probs=probs_list,\n",
    "                colors=[int_colors[class_names.index(i)] for i in label_list],  \n",
    "                font=font_file,\n",
    "            )\n",
    "            annotated_frame = cv2.cvtColor(np.array(annotated_img), cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            video_writer.write(annotated_frame)\n",
    "            pbar.update(1)\n",
    "        else:\n",
    "            break\n",
    "video_capture.release()\n",
    "video_writer.release()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
